# Quotation Generating Chatbot

An innovative AI-powered chatbot that dynamically generates service quotations for customers. This full-stack solution leverages FastAPI on the backend with LLM-enhanced entity extraction and Vue.js on the frontend for a seamless user experience.

---

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
  - [Prerequisites](#prerequisites)
  - [Backend Setup](#backend-setup)
  - [Frontend Setup](#frontend-setup)
  - [Docker Setup (Optional)](#docker-setup-optional)
- [Usage](#usage)
  - [Basic Workflow](#basic-workflow)
  - [Example Conversations](#example-conversations)
- [How It Works](#how-it-works)
  - [Core Components](#core-components)
  - [Technical Implementation](#technical-implementation)
- [Advanced Features](#advanced-features)
  - [Price Range Analysis](#price-range-analysis)
  - [Popular Service Recommendations](#popular-service-recommendations)
- [Performance Optimization](#performance-optimization)
- [Known Limitations](#known-limitations)
- [Future Enhancements](#future-enhancements)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

---

## Overview

The Quotation Generating Chatbot is designed to streamline the process of creating quotations for services such as plumbing, air-conditioning repairs, and installations. By processing user queries through natural language understanding, extracting relevant details, and matching them against a stored dataset, the system produces accurate, ready-to-print quotations in PDF or text formats.

**Key Objectives:**

- **Conversational Interface:** Offers an interactive, human-like conversation flow for collecting service details.
- **Dynamic Quotation Generation:** Produces accurate service quotations based on user inputs and data analysis.
- **Price Range Information:** Provides detailed pricing statistics for different service categories and types.
- **Quotation Management:** Enables easy viewing, downloading, and management of generated quotations.
- **Multi-format Export:** Allows downloading finalized quotations as professional PDFs.

---

## Features

- **üß† Advanced Natural Language Understanding:** Uses Google's Gemini LLM to detect entities (service type, unit type, horsepower, etc.) from conversational inputs.
- **üí∞ Dynamic Price Analysis:** Provides statistical price ranges (min, max, average) for different service categories and types.
- **üìä Data-Driven Recommendations:** Suggests popular services based on historical data analysis.
- **üîç Fuzzy Matching Algorithm:** Finds the most relevant service options even with incomplete information.
- **üìù Automated Quotation Generation:** Creates detailed quotations with pricing, labor charges, and taxes.
- **üîÑ Stateful Conversation Management:** Maintains context throughout the conversation for a natural flow.
- **üì± Responsive UI:** Works seamlessly across desktop and mobile devices.
- **üìÑ PDF & Text Export:** Offers downloadable, professionally formatted quotation documents.
- **üîÑ Session Management:** Supports multiple concurrent user sessions with isolated contexts.
- **üîÑ State Machine Architecture:** Ensures robust conversation flow through different states.

---

## Project Structure
```
quotation-chatbot/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îú‚îÄ‚îÄ chatbot_sqlFinal.py    # Main chatbot logic, entity extraction, matching algorithms
‚îÇ   ‚îú‚îÄ‚îÄ connection.py          # Database connection and data retrieval
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # FastAPI server and API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ temp_quotation.txt     # Example text file for demo/testing
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ QuotationCanvas.vue    # Vue component for rendering/editing a single quotation
‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.vue      # Core chatbot interface component
‚îÇ   ‚îú‚îÄ‚îÄ api.js                 # Axios API integration for backend communication
‚îÇ   ‚îú‚îÄ‚îÄ index.js               # Vuex store setup
‚îÇ   ‚îú‚îÄ‚îÄ main.js                # Vue app entry point
‚îÇ   ‚îú‚îÄ‚îÄ router.js              # Vue Router config (if applicable)
‚îÇ   ‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ chat.js        # Vuex module handling chat-related state
‚îÇ   ‚îú‚îÄ‚îÄ views/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HomeView.vue       # Landing/Home page view
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AboutView.vue      # Example additional page
‚îÇ   ‚îú‚îÄ‚îÄ App.vue                # Root Vue component
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ package-lock.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ node_modules/              # Frontend dependencies (generated by npm/yarn)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md                  # This README file
‚îî‚îÄ‚îÄ ...
```
---

## Installation & Setup

### Prerequisites

- **Python 3.8+**
- **Node.js (v14+) and npm/yarn**
- **Google Gemini API key**
- **PostgreSQL database** (or compatible alternative)

### Backend Setup

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/quotation-chatbot.git
   cd quotation-chatbot
   ```
2. Create and activate a virtual environment:

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3. Install Python dependencies:
    ```bash
    cd backend
    pip install -r requirements.txt
    ```

4. Create a .env file in the backend directory with:

    ```env
    GEMINI_API_KEY=your_gemini_api_key_here
    DATABASE_URL=postgresql://username:password@localhost:5432/quotation_db
    ```

5. Run the FastAPI server:

    ```bash
    uvicorn main:app --reload
    ```

    The API will be available at `http://127.0.0.1:8000`

### Frontend Setup
1. Navigate to the frontend directory:

    ```bash
    cd ../frontend
    ```
2. Install Node dependencies:
    ```bash
    npm install
    # or
    yarn install
    ```

3. Configure environment variables:

   Create a `.env` file in the frontend directory with:

    ```env
    VITE_API_URL=http://localhost:8000/api
    ```

5. Run the development server:
    ```bash
    npm run dev
    # or
    yarn dev
    ```
    The frontend will be available at `http://localhost:3000`

### Docker Setup (Optional)
For containerized deployment:
```bash
docker-compose up -d
```

## Usage
### Basic Workflow
1. Start a conversation by asking about a service (e.g., "I need aircon servicing").

2. Answer follow-up questions about specifics (unit type, horsepower, quantity, etc.).

3. Review the generated quotation with pricing details.

4. Confirm or modify the quotation as needed.

5. Download the final quotation as a PDF.

## Example Conversations
### Aircon Servicing Scenario

**User**: "How much for aircon servicing?"

**Bot**: "For Aircon Servicing, prices typically range from RM 0.00 to RM 2690.00, with an average cost of RM 207.47...
Would you like me to provide a specific quotation based on your requirements?"

**User**: "Yes, chemical cleaning for a window unit, 3.0 HP, just 1 unit."

Bot:

```plaintext
SERVICE QUOTATION
------------------------------------------
Service Description: CHEMICAL AIR COND SERVICING (CEILING EXPOSED TYPE) - 3.0HP TO 5.0HP
Quantity: 1
Unit Price: 340.00
Subtotal: 340.00
Labor Charges: 16.25
Tax (6%): 21.38
Total: 377.62
```

This quotation is for CHEMICAL AIR COND SERVICING (CEILING EXPOSED TYPE) - 3.0HP TO 5.0HP with a match score of 66%.
If you would like to proceed with this quotation, please confirm by saying 'Yes' or 'Confirm'.

## Plumbing Scenario
**User**: "I have a leaking toilet"

**Bot**: "How many toilets need service?"

**User**: "Just one"

**Bot**:
```plaintext

SERVICE QUOTATION
------------------------------------------
Service Description: REPAIR TOILET LEAKING
Quantity: 1
Unit Price: 120.00
Subtotal: 120.00
Labor Charges: 16.25
Tax (6%): 8.18
Total: 144.43
````

This quotation is for REPAIR TOILET LEAKING with a match score of 85%.
If you would like to proceed with this quotation, please confirm by saying 'Yes' or 'Confirm'.

## How It Works
### Core Components
- **Entity Extraction**: via Gemini LLM
- **Data Analysis**: via `analyze_data()`
- **Fuzzy Matching**: via `find_matching_services()`
- **State Machine**: manages conversational stages
- **Quotation Generator**: computes totals, taxes, labor, etc.

### Technical Implementation
- **LLM Integration**: Uses the Langchain framework to interact with Google's Gemini LLM.
- **Fuzzy Matching**: Employs the FuzzyWuzzy library for string matching with tolerance for typos and variations.
- **Data Caching**: Implements efficient caching to minimize database calls.
- **PDF Generation**: Uses ReportLab to create professional PDF quotations.
- **State Management**: Maintains conversation context through a state machine architecture.

## Advanced Features
### Price Range Analysis
The system can provide detailed price statistics for different service categories and types.

Example code snippet:
```python
def get_price_estimate(category, service_type=None):
    """Get a price estimate for a category and optional service type based on analyzed data"""
    analysis = analyze_data()
    if category in analysis['category_analysis']:
        stats = analysis['category_analysis'][category]['price_range']
        return f"For {category}, prices typically range from RM {stats['min']:.2f} to RM {stats['max']:.2f}, with an average cost of RM {stats['mean']:.2f}."
    return "Sorry, we don't have pricing data for that service."
```

### Popular Service Recommendations
Analyzes historical data to recommend popular services.

Example code snippet:
```python
def get_popular_services(category, service_type=None):
    """Get popular services for a category and optional service type based on analyzed data"""
    analysis = analyze_data()
    if category in analysis['category_analysis']:
        common_services = analysis['category_analysis'][category]['common_services'][:3]
        if common_services:
            services_text = ", ".join([f"{s['description']} (RM {s['unit_price']:.2f})" for s in common_services])
            return f"Our most popular {category} services include: {services_text}"
    return None
```

## Performance Optimization
### Data Caching
Implements caching to reduce repeated database calls:
```python
_df_cache = None
_data_analysis_cache = None

def get_quotation_data():
    """Get quotation data with caching to avoid repeated database calls"""
    global _df_cache
    if _df_cache is None:
        # Load data from database
        _df_cache = get_quotation_data_as_df()
    return _df_cache
```
### LLM Optimization
- **Direct Response Handling**: Common responses are handled without LLM calls.
- **Context Preservation**: Maintains conversation context to avoid redundant entity extraction.
- **Fallback Mechanisms**: Uses simple pattern matching as a fallback when LLM calls fail.

## Known Limitations
- **Service Matching Accuracy**: The fuzzy matching algorithm may not always find the most appropriate service, especially with ambiguous descriptions.
- **LLM Dependency**: Requires a valid Gemini API key and may be affected by API rate limits or downtime.
- **Limited Service Categories**: Currently optimized for aircon and plumbing services; adding new service categories requires code adjustments.
- **Data Freshness**: Relies on cached data that must be manually refreshed for real-time updates.

## Future Enhancements
- **Multi-language Support**: Add support for additional languages beyond English.
- **Voice Interface**: Integrate speech-to-text and text-to-speech capabilities.
- **Customer Authentication**: Add user accounts and authentication for personalized experiences.
- **Service Provider Integration**: Allow service providers to update their offerings in real-time.
- **Appointment Scheduling**: Integrate with calendar systems for service appointment booking.
- **Payment Processing**: Add payment gateway integration for immediate service booking.

## Contributing
Contributions are welcome! Please follow these steps:
```bash
# Fork & clone
git checkout -b feature/your-feature
git commit -m "Add your feature"
git push origin feature/your-feature
# Submit Pull Request
```

## License
This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements
- **Google Gemini** for providing the LLM capabilities.
- **FastAPI** for the efficient API framework.
- **Vue.js** for the reactive frontend framework.
- **Langchain** for LLM integration tools.
- **FuzzyWuzzy** for fuzzy string matching.

